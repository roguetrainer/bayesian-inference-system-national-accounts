{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Probabilistic National Accounts Balancing\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook introduces the problem of balancing national accounts data and demonstrates why probabilistic programming offers advantages over traditional methods.\n",
    "\n",
    "### What You'll Learn\n",
    "\n",
    "1. What is the System of National Accounts (SNA)?\n",
    "2. Why is data balancing necessary?\n",
    "3. The traditional RAS method\n",
    "4. How Gen.jl improves on RAS\n",
    "5. A worked example with Canadian data\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- Basic understanding of matrix operations\n",
    "- Familiarity with Python and NumPy\n",
    "- No prior knowledge of national accounts or probabilistic programming required!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "from ras_balancing import ras_balance\n",
    "from canada_data import (\n",
    "    simulate_canadian_fof,\n",
    "    format_matrix_display,\n",
    "    SECTORS_SHORT,\n",
    "    INSTRUMENTS_SHORT\n",
    ")\n",
    "\n",
    "# Set display options\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"✓ Libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: The National Accounts Problem\n",
    "\n",
    "### What is the System of National Accounts?\n",
    "\n",
    "The **System of National Accounts (SNA)** is like double-entry bookkeeping for an entire economy. It tracks:\n",
    "\n",
    "- **Production**: What goods and services are produced?\n",
    "- **Income**: How is income distributed across sectors?\n",
    "- **Expenditure**: What do people buy?\n",
    "- **Financial flows**: Who lends to whom?\n",
    "- **Balance sheets**: Who owns what assets and owes what liabilities?\n",
    "\n",
    "The key principle: **Everything must balance**. Every transaction appears twice (as a source and a use of funds), and fundamental identities must hold:\n",
    "\n",
    "$$\\text{Production} = \\text{Income} = \\text{Expenditure}$$ (GDP identity)\n",
    "\n",
    "$$\\sum_{\\text{sectors}} (\\text{Assets} - \\text{Liabilities}) = 0$$ (Financial accounting)\n",
    "\n",
    "### The Data Quality Problem\n",
    "\n",
    "Here's the challenge: data comes from multiple sources with varying reliability:\n",
    "\n",
    "| Data Source | Coverage | Reliability | Examples |\n",
    "|-------------|----------|-------------|----------|\n",
    "| **Administrative data** | Incomplete | Very High | Tax records, central bank data |\n",
    "| **Survey data** | Comprehensive | Medium-Low | Household surveys, business surveys |\n",
    "| **Derived estimates** | Gap-filling | Variable | Residuals, imputations |\n",
    "\n",
    "**The problem**: When you compile data from all sources, the accounting identities don't hold!\n",
    "\n",
    "For example, if you sum up:\n",
    "- Household wealth from surveys\n",
    "- Corporate wealth from tax data  \n",
    "- Government wealth from budget documents\n",
    "- Foreign wealth from balance of payments\n",
    "\n",
    "...the total financial assets won't equal total financial liabilities (they should be equal in a closed system, or differ by the current account in an open economy).\n",
    "\n",
    "### Why This Matters\n",
    "\n",
    "Unbalanced data leads to:\n",
    "- Contradictory policy implications\n",
    "- Loss of user trust\n",
    "- Inability to use data for economic modeling\n",
    "- Missed insights (e.g., hidden debt accumulation)\n",
    "\n",
    "**Example**: If household survey data underreports wealth by 20%, you might think households are poorer than they are, leading to misguided social policy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: A Concrete Example with Canadian Data\n",
    "\n",
    "Let's look at a simplified flow-of-funds matrix for Canada. This shows holdings of financial assets by sector and instrument type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic Canadian data\n",
    "np.random.seed(42)\n",
    "noisy_matrix, true_row_sums, true_col_sums = simulate_canadian_fof(\n",
    "    scale=2000.0,  # 2 trillion CAD\n",
    "    noise_level=0.15,  # 15% measurement error\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Display the preliminary data\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PRELIMINARY DATA (Before Balancing)\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nThis is what we observe from combining different data sources:\")\n",
    "print()\n",
    "\n",
    "df_noisy = pd.DataFrame(\n",
    "    noisy_matrix,\n",
    "    index=SECTORS_SHORT,\n",
    "    columns=INSTRUMENTS_SHORT[:noisy_matrix.shape[1]]\n",
    ")\n",
    "\n",
    "# Add row sums\n",
    "df_noisy['Row Sum'] = df_noisy.sum(axis=1)\n",
    "print(df_noisy.to_string())\n",
    "print()\n",
    "\n",
    "# Show the imbalance\n",
    "observed_row_sums = noisy_matrix.sum(axis=1)\n",
    "observed_col_sums = noisy_matrix.sum(axis=0)\n",
    "\n",
    "print(\"\\nTarget Row Sums (from administrative data):\")\n",
    "print(f\"  {true_row_sums}\")\n",
    "print(\"\\nObserved Row Sums (from preliminary data):\")\n",
    "print(f\"  {observed_row_sums}\")\n",
    "print(\"\\nRow Discrepancies:\")\n",
    "print(f\"  {observed_row_sums - true_row_sums}\")\n",
    "print(f\"\\n⚠️  The data doesn't balance! This is the problem we need to solve.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Row discrepancies\n",
    "row_errors = observed_row_sums - true_row_sums\n",
    "colors_row = ['red' if x < 0 else 'green' for x in row_errors]\n",
    "ax1.barh(SECTORS_SHORT, row_errors, color=colors_row, alpha=0.7)\n",
    "ax1.axvline(0, color='black', linewidth=0.5)\n",
    "ax1.set_xlabel('Discrepancy (Billions CAD)', fontsize=11)\n",
    "ax1.set_title('Row Sum Errors\\n(Observed - Target)', fontsize=12, fontweight='bold')\n",
    "ax1.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Column discrepancies\n",
    "col_errors = observed_col_sums - true_col_sums\n",
    "instruments_used = INSTRUMENTS_SHORT[:len(col_errors)]\n",
    "colors_col = ['red' if x < 0 else 'green' for x in col_errors]\n",
    "ax2.bar(instruments_used, col_errors, color=colors_col, alpha=0.7)\n",
    "ax2.axhline(0, color='black', linewidth=0.5)\n",
    "ax2.set_ylabel('Discrepancy (Billions CAD)', fontsize=11)\n",
    "ax2.set_title('Column Sum Errors\\n(Observed - Target)', fontsize=12, fontweight='bold')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Red bars = Underestimated, Green bars = Overestimated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: The Traditional Solution - RAS Method\n",
    "\n",
    "### What is RAS?\n",
    "\n",
    "The **RAS algorithm** (named after economists Richard Stone and collaborators) is the standard method for balancing matrices. It works by:\n",
    "\n",
    "1. **R step**: Scale rows to match target row sums\n",
    "2. **A step**: (The original matrix - stored but not explicitly in the iteration)\n",
    "3. **S step**: Scale columns to match target column sums  \n",
    "4. **Repeat** until convergence\n",
    "\n",
    "Mathematically:\n",
    "\n",
    "$$B = \\hat{R} \\cdot A \\cdot \\hat{S}$$\n",
    "\n",
    "where $\\hat{R}$ and $\\hat{S}$ are diagonal scaling matrices.\n",
    "\n",
    "### Running RAS on Our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run RAS balancing\n",
    "ras_result = ras_balance(\n",
    "    noisy_matrix,\n",
    "    true_row_sums,\n",
    "    true_col_sums,\n",
    "    tolerance=1e-6,\n",
    "    max_iter=1000\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RAS BALANCED MATRIX\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "df_ras = pd.DataFrame(\n",
    "    ras_result,\n",
    "    index=SECTORS_SHORT,\n",
    "    columns=INSTRUMENTS_SHORT[:ras_result.shape[1]]\n",
    ")\n",
    "df_ras['Row Sum'] = df_ras.sum(axis=1)\n",
    "print(df_ras.to_string())\n",
    "\n",
    "# Verify constraints\n",
    "print(\"\\nVerification:\")\n",
    "ras_row_sums = ras_result.sum(axis=1)\n",
    "ras_col_sums = ras_result.sum(axis=0)\n",
    "print(f\"  Max row error: {np.abs(ras_row_sums - true_row_sums).max():.2e}\")\n",
    "print(f\"  Max col error: {np.abs(ras_col_sums - true_col_sums).max():.2e}\")\n",
    "print(\"\\n✓ Constraints satisfied!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Did RAS Adjust the Data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate adjustments\n",
    "ras_adjustments = ras_result - noisy_matrix\n",
    "ras_pct_adjustments = 100 * ras_adjustments / (noisy_matrix + 1e-10)\n",
    "\n",
    "# Visualize adjustments\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Absolute adjustments\n",
    "sns.heatmap(\n",
    "    ras_adjustments,\n",
    "    annot=True,\n",
    "    fmt='.1f',\n",
    "    cmap='RdBu_r',\n",
    "    center=0,\n",
    "    xticklabels=INSTRUMENTS_SHORT[:ras_result.shape[1]],\n",
    "    yticklabels=SECTORS_SHORT,\n",
    "    ax=ax1,\n",
    "    cbar_kws={'label': 'Billions CAD'}\n",
    ")\n",
    "ax1.set_title('RAS Adjustments (Absolute)', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Percentage adjustments\n",
    "sns.heatmap(\n",
    "    ras_pct_adjustments,\n",
    "    annot=True,\n",
    "    fmt='.1f',\n",
    "    cmap='RdBu_r',\n",
    "    center=0,\n",
    "    xticklabels=INSTRUMENTS_SHORT[:ras_result.shape[1]],\n",
    "    yticklabels=SECTORS_SHORT,\n",
    "    ax=ax2,\n",
    "    cbar_kws={'label': 'Percent'}\n",
    ")\n",
    "ax2.set_title('RAS Adjustments (Percentage)', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Blue = Decreased, Red = Increased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: The Problem with RAS\n",
    "\n",
    "### RAS Treats All Data Equally\n",
    "\n",
    "The fundamental limitation of RAS is that it applies proportional adjustments **without considering data quality**.\n",
    "\n",
    "Consider:\n",
    "- Government balance sheet data from official records (very reliable)\n",
    "- Household cash holdings from surveys (people forget, underreport)\n",
    "\n",
    "**RAS scales both by the same proportion!** This is suboptimal.\n",
    "\n",
    "### What We Really Want\n",
    "\n",
    "Ideally, we want to:\n",
    "\n",
    "1. **Respect data quality**: Adjust unreliable data more than reliable data\n",
    "2. **Quantify uncertainty**: Give confidence intervals, not just point estimates\n",
    "3. **Incorporate domain knowledge**: Use institutional facts (e.g., \"banks hold most mortgages\")\n",
    "4. **Detect anomalies**: Flag suspicious data points automatically\n",
    "\n",
    "This is where **probabilistic programming** with Gen.jl comes in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: The Gen.jl Approach\n",
    "\n",
    "### Key Idea: Model Data Quality Explicitly\n",
    "\n",
    "Instead of treating constraints as hard requirements, Gen.jl models them as **probabilistic observations** with uncertainty:\n",
    "\n",
    "```julia\n",
    "# In Gen.jl model:\n",
    "{:row_targets => r} ~ Normal(calculated_row_sum, σ_r)\n",
    "```\n",
    "\n",
    "Where:\n",
    "- **Small σ**: High confidence in this data (e.g., government records)\n",
    "- **Large σ**: Low confidence (e.g., household surveys)\n",
    "\n",
    "### The Gen.jl Workflow\n",
    "\n",
    "1. **Define a generative model**: How is the data produced?\n",
    "2. **Specify priors**: Start with preliminary estimates\n",
    "3. **Set uncertainty**: Encode data quality as variance parameters\n",
    "4. **Run inference**: Find the most likely balanced matrix\n",
    "5. **Analyze posterior**: Get uncertainty estimates\n",
    "\n",
    "### Running Gen.jl (Julia Code)\n",
    "\n",
    "The Gen.jl code is in `src/gen_balancing.jl` and `examples/simple_balance.jl`. To run it:\n",
    "\n",
    "```bash\n",
    "julia --project=. examples/simple_balance.jl\n",
    "```\n",
    "\n",
    "Or see notebook `03_gen_balancing.ipynb` for interactive Julia examples.\n",
    "\n",
    "### How Gen.jl Differs from RAS\n",
    "\n",
    "| Aspect | RAS | Gen.jl |\n",
    "|--------|-----|--------|\n",
    "| Data quality | All equal | Explicitly modeled |\n",
    "| Constraints | Hard (must satisfy) | Soft (weighted by σ) |\n",
    "| Output | Single matrix | Posterior distribution |\n",
    "| Adjustments | Proportional | Targeted to high-uncertainty cells |\n",
    "| Domain knowledge | Limited | Fully customizable |\n",
    "| Anomaly detection | Manual | Automatic via likelihood |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Comparing Results\n",
    "\n",
    "Let's compare what RAS and Gen.jl do differently.\n",
    "\n",
    "### Scenario: Household Wealth Underreporting\n",
    "\n",
    "Suppose we know:\n",
    "- Household survey data is unreliable (people underreport wealth)\n",
    "- Government data is from official budget documents (very reliable)\n",
    "\n",
    "**Question**: When balancing, should adjustments be concentrated in household data or spread equally?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show where adjustments went\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"WHERE DID RAS PUT THE ADJUSTMENTS?\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Calculate total adjustment per sector\n",
    "adjustment_by_sector = np.abs(ras_adjustments).sum(axis=1)\n",
    "\n",
    "print(\"\\nTotal Absolute Adjustment by Sector:\")\n",
    "for sector, adj in zip(SECTORS_SHORT, adjustment_by_sector):\n",
    "    pct = 100 * adj / adjustment_by_sector.sum()\n",
    "    print(f\"  {sector:6s}: {adj:8.2f} CAD billion ({pct:5.1f}% of total adjustments)\")\n",
    "\n",
    "print(\"\\nKey observation:\")\n",
    "print(\"  RAS spreads adjustments proportionally across all sectors,\")\n",
    "print(\"  even though we know household data is less reliable than government data.\")\n",
    "print(\"\\n  Gen.jl would concentrate adjustments where uncertainty is highest!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Next Steps\n",
    "\n",
    "### Explore More in This Package\n",
    "\n",
    "1. **`02_ras_method.ipynb`**: Deep dive into RAS algorithm\n",
    "2. **`03_gen_balancing.ipynb`**: Interactive Gen.jl tutorial\n",
    "3. **`04_comparison.ipynb`**: Side-by-side RAS vs Gen analysis\n",
    "4. **`05_uncertainty.ipynb`**: Working with posterior distributions\n",
    "5. **`06_anomalies.ipynb`**: Detecting outliers and data errors\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "✓ National accounts data rarely balances due to heterogeneous sources  \n",
    "✓ RAS is fast and simple but treats all data equally  \n",
    "✓ Gen.jl allows explicit modeling of data quality  \n",
    "✓ Probabilistic programming gives uncertainty quantification  \n",
    "✓ This approach is novel in official statistics (as far as we know!)  \n",
    "\n",
    "### Further Reading\n",
    "\n",
    "- **SNA Overview**: `docs/OVERVIEW.md`\n",
    "- **Gen.jl Documentation**: https://www.gen.dev\n",
    "- **Statistics Canada**: www23.statcan.gc.ca/imdb/\n",
    "- **Godley & Lavoie (2007)**: *Monetary Economics* (the SFC bible)\n",
    "\n",
    "### Questions?\n",
    "\n",
    "Open an issue on GitHub or explore the documentation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Thank you for exploring probabilistic national accounts!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nRemember: Good accounting is good economics.\")\n",
    "print(\"          - Wynne Godley\")\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
